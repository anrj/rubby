### **Function Specification**

**Team Name:** Rubby the Duck 
**Project:** Rubby the Duck
**Date:** Week 6, [11/6/2025]

---
### Overview

**Number of Functions:** 2
**Purpose of Function Calling in Our Project:**
Our AI, Rubby, has a primary goal of guiding users through Socratic dialogue. However, at key moments, it needs to perform specific, structured actions: escalating the complexity of its reasoning when a user is stuck, or formally concluding a session when a user has reached an insight. Function calling gives the AI a reliable toolkit to invoke these state changes, allowing it to decide *when* to use a more powerful model or *when* to end the session, separating the conversational flow from these critical system actions.

---
### Function Calling Flow

Here's how function calling will work in our system:
```
1. User Query → "I'm really stuck, I don't know what to ask next."
2. AI Decision → The AI (GPT-4o-mini) determines the user needs a more insightful question.
3. Function Call → AI generates {"function": "escalate_for_insight", "arguments": {"current_topic": "recursion", "user_difficulty": "high"}}
4. OUR CODE executes → We run escalate_for_insight(...), which takes the conversation history and re-submits it to the more powerful GPT-4o model.
5. Function Result → Our code gets a more profound question back from the powerful LLM.
6. AI Response → The original LLM receives this new question and synthesizes a final, natural-language response for the user.
7. User Sees Result → "That's a common feeling when exploring this. Let’s try a different angle: Instead of focusing on the code, can you describe a real-world object that has parts that are smaller versions of itself?"```
**Critical Point:** Function calling is our mechanism for **model routing** and **session state management**. The cheap model decides *when* to call the expensive model or end the session.

---
### Function 1: `escalate_for_insight`

#### Basic Information
**Function Name:** `escalate_for_insight`
**Purpose:** Re-routes the conversation to a more powerful AI model (GPT-4o) when the user is stuck or the topic becomes highly complex, in order to generate a more insightful question.
**When AI Should Call This:**
- User explicitly states they are stuck, confused, or don't know the answer.
- The conversation has gone in circles for several turns without progress.
- The user asks a deeply abstract or philosophical question that requires more advanced reasoning.

#### Parameters
```markdown
| Parameter | Type | Required | Validation | Description |
|---|---|---|---|---|
| `reason` | string | Yes | 10-150 characters | A brief explanation of why escalation is needed, e.g., "User is stuck on the concept of recursion." |
| `topic` | string | No | N/A | The core topic of the conversation, e.g., "Linked Lists," "JavaScript Promises." |
```

#### Return Structure
**On Success:**
```json
{
  "status": "success",
  "data": {
    "new_question": "Instead of thinking about code, can you describe a set of Russian nesting dolls? How does that relate to our topic?"
  }
}
```
**On Error:**
```json
{
  "status": "error",
  "error_code": "ESCALATION_FAILED",
  "error_message": "The advanced AI was unable to generate a better question."
}
```

#### JSON Schema (For the LLM - GPT-4o-mini)
```json
{
  "name": "escalate_for_insight",
  "description": "Call this function when the user is stuck or confused and needs a more insightful or creative question to get them unstuck. This will use a more powerful AI to help.",
  "parameters": {
    "type": "object",
    "properties": {
      "reason": {
        "type": "string",
        "description": "A short summary of why the user needs help. For example: 'The user is confused about the base case in recursion.' or 'User expressed frustration.'"
      },
      "topic": {
        "type": "string",
        "description": "The main subject of the conversation, for example: 'CSS specificity' or 'the event loop'."
      }
    },
    "required": ["reason"]
  }
}
```

#### Safety Considerations
- **Content Moderation:** The final question generated by the escalated model (GPT-4o) is subject to OpenAI's content filters.
- **Cost Control:** This function is the primary gateway to our more expensive model. We will monitor its usage frequency closely to ensure costs remain within budget.

---
### Function 2: `conclude_session`

#### Basic Information
**Function Name:** `conclude_session`
**Purpose:** Formally ends the learning session and prepares a summary of key insights the user has identified.
**When AI Should Call This:**
- The user indicates they have reached an understanding (e.g., "Oh, I get it now!").
- The conversation has reached a logical conclusion.
- The user explicitly asks to end the session.

#### Parameters
```markdown
| Parameter | Type | Required | Validation | Description |
|---|---|---|---|---|
| `summary_title` | string | Yes | 5-100 characters | A concise title for the session, e.g., "Understanding Recursion." |
| `final_insight` | string | Yes | 20-200 characters | The user's key takeaway or "aha!" moment that concluded the discussion. |
```

#### Return Structure
**On Success:**
```json
{
  "status": "success",
  "data": {
    "session_ended": true,
    "summary_title": "Understanding Recursion",
    "key_insights": [
      "Insight 1 flagged by user earlier...",
      "Insight 2 flagged by user earlier...",
      "The base case is like the smallest Russian nesting doll."
    ]
  }
}
```
**On Error:**
```json
{
  "status": "error",
  "error_code": "SUMMARY_FAILED",
  "error_message": "Could not generate a valid session summary."
}
```

#### JSON Schema (For the LLM)
```json
{
  "name": "conclude_session",
  "description": "Ends the current learning session. Use this when the user has reached a clear understanding or says they are finished.",
  "parameters": {
    "type": "object",
    "properties": {
      "summary_title": {
        "type": "string",
        "description": "A short, descriptive title for the completed session. For example: 'Figuring out CSS Flexbox' or 'The Basics of Asynchronous Code'."
      },
      "final_insight": {
        "type": "string",
        "description": "The user's final statement of understanding that triggered the end of the session."
      }
    },
    "required": ["summary_title", "final_insight"]
  }
}
```

#### Safety Considerations
- **Data Handling:** This function gathers user-identified insights for the summary. No other user data is processed. The summary is ephemeral and is not stored on the backend.

---
### Function Calling Implementation Plan

*   **Week 6:** Implement the `escalate_for_insight` function. Test the full model-routing loop.
*   **Week 7:** Implement the `conclude_session` function. Add proper error handling for both functions.
*   **Week 8:** Test edge cases (e.g., user tries to end the session immediately) and refine the function descriptions for the AI to improve its decision-making accuracy.

---
### Error Code Reference
```markdown
| Error Code | HTTP Status | Meaning | User-Facing Message |
|---|---|---|---|
| `ESCALATION_FAILED` | 500 | The GPT-4o model failed to return a valid question. | "I'm sorry, I'm having a little trouble thinking of a new angle. Could you try asking me about that in a different way?" |
| `SUMMARY_FAILED` | 500 | The backend failed to compile the list of insights. | "It seems I had trouble putting my notes together. Let's just call it a successful session!" |
| `INVALID_SESSION_STATE` | 400 | User tried to end a session that hadn't properly started. | "We're just getting started! What's the first thing on your mind?" |
```

---
### Testing Strategy

#### Unit Tests
- For `escalate_for_insight`, test that the function correctly calls the `gpt-4o` model client when invoked (mocked).
- For `conclude_session`, test that the function correctly gathers insights from a sample conversation history and formats them.
- Test that both functions return the correct error structure if their underlying logic fails.

#### Integration Tests
- Test the full loop for `escalate_for_insight`: send a user query like "I'm stuck" and assert that the OpenAI client for `gpt-4o` is called.
- Test the full loop for `conclude_session`: send a user query like "I get it now" and assert that the final response indicates the session has ended.

---
### Performance Metrics
- **Function Execution Time:** The Python code for the function itself should execute in < 50ms.
- **Total Query Time (including LLM):**
    - `escalate_for_insight`: < 3 seconds
    - `conclude_session`: < 2 seconds
- **Success Rate:** > 99% of valid triggers should result in a successful function execution.